{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3.3 - Détection d'anomalies\n",
    "\n",
    "Ce notebook identifie les anomalies dans les données de consommation énergétique des bâtiments.  \n",
    "Plusieurs méthodes complémentaires sont utilisées :\n",
    "- Pics de consommation (3 écarts-types)\n",
    "- Méthode IQR (interquartile range)\n",
    "- Sous-consommation suspecte\n",
    "- Incohérences DPE / consommation réelle\n",
    "- Anomalies temporelles\n",
    "\n",
    "**Source** : `../output/consommations_enrichies.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports et chargement des données enrichies ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chargement du fichier parquet enrichi\n",
    "df = pd.read_parquet('../output/consommations_enrichies.parquet')\n",
    "\n",
    "print(f\"Nombre d'enregistrements : {len(df):,}\")\n",
    "print(f\"Nombre de bâtiments     : {df['batiment_id'].nunique()}\")\n",
    "print(f\"Période                 : {df['timestamp'].min()} → {df['timestamp'].max()}\")\n",
    "print(f\"\\nColonnes disponibles :\")\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pics de consommation anormaux (méthode des 3 écarts-types)\n",
    "\n",
    "Pour chaque couple (bâtiment, type d'énergie), on calcule la moyenne et l'écart-type de la consommation.  \n",
    "Tout enregistrement dont la consommation dépasse **moyenne + 3σ** est considéré comme un pic anormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Détection des pics de consommation par la méthode 3-sigma ===\n",
    "\n",
    "# Calcul de la moyenne et de l'écart-type par bâtiment et type d'énergie\n",
    "stats_batiment = (\n",
    "    df.groupby(['batiment_id', 'nom', 'type_energie'])['consommation']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "stats_batiment.columns = ['batiment_id', 'nom', 'type_energie', 'conso_mean', 'conso_std']\n",
    "\n",
    "# Jointure pour ajouter les seuils au dataframe principal\n",
    "df_sigma = df.merge(stats_batiment, on=['batiment_id', 'nom', 'type_energie'], how='left')\n",
    "\n",
    "# Seuil haut : moyenne + 3 écarts-types\n",
    "df_sigma['seuil_3sigma'] = df_sigma['conso_mean'] + 3 * df_sigma['conso_std']\n",
    "\n",
    "# Flaguer les anomalies\n",
    "df_sigma['anomalie_3sigma'] = df_sigma['consommation'] > df_sigma['seuil_3sigma']\n",
    "\n",
    "anomalies_3sigma = df_sigma[df_sigma['anomalie_3sigma']].copy()\n",
    "\n",
    "print(f\"Nombre total d'anomalies détectées (3σ) : {len(anomalies_3sigma)}\")\n",
    "print(f\"Pourcentage du jeu de données            : {len(anomalies_3sigma)/len(df)*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Top 20 des anomalies les plus importantes (écart le plus fort)\n",
    "anomalies_3sigma['ecart_relatif'] = (\n",
    "    (anomalies_3sigma['consommation'] - anomalies_3sigma['conso_mean'])\n",
    "    / anomalies_3sigma['conso_std']\n",
    ")\n",
    "\n",
    "top20 = anomalies_3sigma.nlargest(20, 'ecart_relatif')[\n",
    "    ['batiment_id', 'nom', 'type_energie', 'timestamp', 'consommation',\n",
    "     'conso_mean', 'conso_std', 'ecart_relatif']\n",
    "]\n",
    "\n",
    "print(\"=== Top 20 des pics de consommation les plus anormaux ===\")\n",
    "display(top20)\n",
    "\n",
    "# Nombre d'anomalies par bâtiment\n",
    "anomalies_par_batiment_3sigma = (\n",
    "    anomalies_3sigma.groupby(['batiment_id', 'nom'])\n",
    "    .size()\n",
    "    .reset_index(name='nb_anomalies_3sigma')\n",
    "    .sort_values('nb_anomalies_3sigma', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n=== Nombre d'anomalies 3σ par bâtiment ===\")\n",
    "display(anomalies_par_batiment_3sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Méthode IQR pour la détection d'outliers\n",
    "\n",
    "Méthode alternative basée sur l'écart interquartile (IQR = Q3 − Q1).  \n",
    "Un outlier est défini comme toute valeur en dehors de l'intervalle **[Q1 − 1.5×IQR, Q3 + 1.5×IQR]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Détection d'outliers par la méthode IQR ===\n",
    "\n",
    "# Calcul des quartiles par bâtiment et type d'énergie\n",
    "quartiles = (\n",
    "    df.groupby(['batiment_id', 'nom', 'type_energie'])['consommation']\n",
    "    .quantile([0.25, 0.75])\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    ")\n",
    "quartiles.columns = ['batiment_id', 'nom', 'type_energie', 'Q1', 'Q3']\n",
    "quartiles['IQR'] = quartiles['Q3'] - quartiles['Q1']\n",
    "quartiles['seuil_bas_iqr'] = quartiles['Q1'] - 1.5 * quartiles['IQR']\n",
    "quartiles['seuil_haut_iqr'] = quartiles['Q3'] + 1.5 * quartiles['IQR']\n",
    "\n",
    "# Jointure avec le dataframe principal\n",
    "df_iqr = df.merge(quartiles, on=['batiment_id', 'nom', 'type_energie'], how='left')\n",
    "\n",
    "# Flaguer les outliers (hauts et bas)\n",
    "df_iqr['outlier_iqr_haut'] = df_iqr['consommation'] > df_iqr['seuil_haut_iqr']\n",
    "df_iqr['outlier_iqr_bas'] = df_iqr['consommation'] < df_iqr['seuil_bas_iqr']\n",
    "df_iqr['outlier_iqr'] = df_iqr['outlier_iqr_haut'] | df_iqr['outlier_iqr_bas']\n",
    "\n",
    "outliers_iqr = df_iqr[df_iqr['outlier_iqr']].copy()\n",
    "\n",
    "print(f\"Nombre d'outliers IQR détectés : {len(outliers_iqr)}\")\n",
    "print(f\"  - Outliers hauts             : {df_iqr['outlier_iqr_haut'].sum()}\")\n",
    "print(f\"  - Outliers bas               : {df_iqr['outlier_iqr_bas'].sum()}\")\n",
    "print(f\"Pourcentage du jeu de données  : {len(outliers_iqr)/len(df)*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Comparaison des deux méthodes\n",
    "print(\"=== Comparaison des méthodes de détection ===\")\n",
    "print(f\"Anomalies 3-sigma : {len(anomalies_3sigma)}\")\n",
    "print(f\"Outliers IQR      : {len(outliers_iqr)}\")\n",
    "\n",
    "# Identification des enregistrements détectés par les deux méthodes\n",
    "idx_3sigma = set(anomalies_3sigma.index)\n",
    "idx_iqr_haut = set(df_iqr[df_iqr['outlier_iqr_haut']].index)\n",
    "communs = idx_3sigma & idx_iqr_haut\n",
    "print(f\"Détectés par les deux méthodes (pics hauts) : {len(communs)}\")\n",
    "print()\n",
    "\n",
    "# Bâtiments avec le plus d'outliers IQR\n",
    "outliers_par_batiment_iqr = (\n",
    "    outliers_iqr.groupby(['batiment_id', 'nom'])\n",
    "    .size()\n",
    "    .reset_index(name='nb_outliers_iqr')\n",
    "    .sort_values('nb_outliers_iqr', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"=== Bâtiments avec le plus d'outliers IQR ===\")\n",
    "display(outliers_par_batiment_iqr.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Périodes de sous-consommation suspectes\n",
    "\n",
    "Identification des périodes où un bâtiment présente une consommation anormalement basse  \n",
    "(< moyenne − 2σ) **pendant les heures ouvrables** (jours de semaine, 8h-18h).  \n",
    "Ces périodes peuvent indiquer des fermetures non signalées ou des pannes de compteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Détection des périodes de sous-consommation suspectes ===\n",
    "\n",
    "# Filtrer les heures ouvrables (lundi=0 à vendredi=4, 8h à 18h)\n",
    "df_ouvrable = df.copy()\n",
    "df_ouvrable['timestamp'] = pd.to_datetime(df_ouvrable['timestamp'])\n",
    "df_ouvrable['jour_num'] = df_ouvrable['timestamp'].dt.dayofweek  # 0=lundi, 6=dimanche\n",
    "\n",
    "mask_heures_ouvrables = (\n",
    "    (df_ouvrable['jour_num'] < 5) &  # Lundi à vendredi\n",
    "    (df_ouvrable['heure'] >= 8) &\n",
    "    (df_ouvrable['heure'] <= 18)\n",
    ")\n",
    "df_ouvrable = df_ouvrable[mask_heures_ouvrables].copy()\n",
    "\n",
    "# Calcul de la moyenne et de l'écart-type en heures ouvrables\n",
    "stats_ouvrable = (\n",
    "    df_ouvrable.groupby(['batiment_id', 'nom', 'type_energie'])['consommation']\n",
    "    .agg(['mean', 'std'])\n",
    "    .reset_index()\n",
    ")\n",
    "stats_ouvrable.columns = ['batiment_id', 'nom', 'type_energie', 'mean_ouvr', 'std_ouvr']\n",
    "\n",
    "# Jointure et détection de sous-consommation\n",
    "df_ouvrable = df_ouvrable.merge(stats_ouvrable, on=['batiment_id', 'nom', 'type_energie'], how='left')\n",
    "df_ouvrable['seuil_bas_2sigma'] = df_ouvrable['mean_ouvr'] - 2 * df_ouvrable['std_ouvr']\n",
    "df_ouvrable['sous_conso'] = df_ouvrable['consommation'] < df_ouvrable['seuil_bas_2sigma']\n",
    "\n",
    "sous_conso = df_ouvrable[df_ouvrable['sous_conso']].copy()\n",
    "\n",
    "print(f\"Enregistrements en sous-consommation suspecte : {len(sous_conso)}\")\n",
    "print(f\"Pourcentage des heures ouvrables              : {len(sous_conso)/len(df_ouvrable)*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Détection des périodes prolongées de quasi-zéro consommation (> 24h)\n",
    "# On considère \"quasi-zéro\" comme < 5% de la moyenne\n",
    "df_ouvrable['quasi_zero'] = df_ouvrable['consommation'] < (df_ouvrable['mean_ouvr'] * 0.05)\n",
    "\n",
    "periodes_zero = []\n",
    "for (bat_id, nom, energie), group in df_ouvrable.groupby(['batiment_id', 'nom', 'type_energie']):\n",
    "    group = group.sort_values('timestamp')\n",
    "    quasi_zero_mask = group['quasi_zero'].values\n",
    "    timestamps = group['timestamp'].values\n",
    "    \n",
    "    if len(timestamps) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Identifier les séquences consécutives de quasi-zéro\n",
    "    in_sequence = False\n",
    "    debut = None\n",
    "    \n",
    "    for i in range(len(quasi_zero_mask)):\n",
    "        if quasi_zero_mask[i] and not in_sequence:\n",
    "            in_sequence = True\n",
    "            debut = timestamps[i]\n",
    "        elif not quasi_zero_mask[i] and in_sequence:\n",
    "            in_sequence = False\n",
    "            fin = timestamps[i - 1]\n",
    "            duree_heures = (pd.Timestamp(fin) - pd.Timestamp(debut)).total_seconds() / 3600\n",
    "            if duree_heures > 24:\n",
    "                periodes_zero.append({\n",
    "                    'batiment_id': bat_id,\n",
    "                    'nom': nom,\n",
    "                    'type_energie': energie,\n",
    "                    'debut': debut,\n",
    "                    'fin': fin,\n",
    "                    'duree_heures': round(duree_heures, 1)\n",
    "                })\n",
    "    \n",
    "    # Vérifier la dernière séquence\n",
    "    if in_sequence:\n",
    "        fin = timestamps[-1]\n",
    "        duree_heures = (pd.Timestamp(fin) - pd.Timestamp(debut)).total_seconds() / 3600\n",
    "        if duree_heures > 24:\n",
    "            periodes_zero.append({\n",
    "                'batiment_id': bat_id,\n",
    "                'nom': nom,\n",
    "                'type_energie': energie,\n",
    "                'debut': debut,\n",
    "                'fin': fin,\n",
    "                'duree_heures': round(duree_heures, 1)\n",
    "            })\n",
    "\n",
    "df_periodes_zero = pd.DataFrame(periodes_zero)\n",
    "\n",
    "if len(df_periodes_zero) > 0:\n",
    "    df_periodes_zero = df_periodes_zero.sort_values('duree_heures', ascending=False)\n",
    "    print(f\"Périodes prolongées (>24h) de quasi-zéro consommation : {len(df_periodes_zero)}\")\n",
    "    display(df_periodes_zero.head(20))\n",
    "else:\n",
    "    print(\"Aucune période prolongée de quasi-zéro consommation détectée.\")\n",
    "\n",
    "# Bâtiments les plus touchés par la sous-consommation\n",
    "sous_conso_par_bat = (\n",
    "    sous_conso.groupby(['batiment_id', 'nom'])\n",
    "    .size()\n",
    "    .reset_index(name='nb_sous_conso')\n",
    "    .sort_values('nb_sous_conso', ascending=False)\n",
    ")\n",
    "print(\"\\n=== Bâtiments les plus touchés par la sous-consommation ===\")\n",
    "display(sous_conso_par_bat.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Incohérences entre DPE et consommation réelle\n",
    "\n",
    "Comparaison de la consommation réelle par m² avec les plages attendues  \n",
    "selon la classe énergétique (DPE) du bâtiment.\n",
    "\n",
    "| Classe | Plage (kWh/m²/an) |\n",
    "|--------|-------------------|\n",
    "| A      | < 70              |\n",
    "| B      | 70 – 110          |\n",
    "| C      | 110 – 180         |\n",
    "| D      | 180 – 250         |\n",
    "| E      | 250 – 330         |\n",
    "| F      | 330 – 420         |\n",
    "| G      | > 420             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Incohérences entre classe DPE et consommation réelle ===\n",
    "\n",
    "# Plages de référence DPE (kWh/m²/an)\n",
    "dpe_ranges = {\n",
    "    'A': (0, 70),\n",
    "    'B': (70, 110),\n",
    "    'C': (110, 180),\n",
    "    'D': (180, 250),\n",
    "    'E': (250, 330),\n",
    "    'F': (330, 420),\n",
    "    'G': (420, float('inf'))\n",
    "}\n",
    "\n",
    "# Calcul de la consommation annuelle par m² pour chaque bâtiment\n",
    "# On agrège par bâtiment pour obtenir la consommation totale annuelle\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['annee'] = df['timestamp'].dt.year\n",
    "\n",
    "conso_annuelle = (\n",
    "    df.groupby(['batiment_id', 'nom', 'classe_energetique', 'surface_m2', 'annee'])\n",
    "    .agg(conso_totale=('consommation', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Consommation par m² annuelle\n",
    "conso_annuelle['conso_par_m2_an'] = conso_annuelle['conso_totale'] / conso_annuelle['surface_m2']\n",
    "\n",
    "# Moyenne sur les années disponibles\n",
    "conso_moyenne_bat = (\n",
    "    conso_annuelle.groupby(['batiment_id', 'nom', 'classe_energetique', 'surface_m2'])\n",
    "    .agg(conso_par_m2_an_moy=('conso_par_m2_an', 'mean'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Vérification de la cohérence avec la classe DPE\n",
    "def verifier_coherence_dpe(row):\n",
    "    \"\"\"Vérifie si la consommation réelle est cohérente avec la classe DPE.\"\"\"\n",
    "    classe = row['classe_energetique']\n",
    "    conso = row['conso_par_m2_an_moy']\n",
    "    \n",
    "    if classe not in dpe_ranges:\n",
    "        return 'classe_inconnue'\n",
    "    \n",
    "    borne_basse, borne_haute = dpe_ranges[classe]\n",
    "    \n",
    "    if conso < borne_basse:\n",
    "        return 'sous_classe'  # Consomme moins que sa classe\n",
    "    elif conso > borne_haute:\n",
    "        return 'sur_classe'   # Consomme plus que sa classe\n",
    "    else:\n",
    "        return 'coherent'\n",
    "\n",
    "def trouver_classe_reelle(conso):\n",
    "    \"\"\"Détermine la classe DPE réelle en fonction de la consommation.\"\"\"\n",
    "    for classe, (borne_basse, borne_haute) in dpe_ranges.items():\n",
    "        if borne_basse <= conso < borne_haute:\n",
    "            return classe\n",
    "    return 'G'\n",
    "\n",
    "conso_moyenne_bat['coherence_dpe'] = conso_moyenne_bat.apply(verifier_coherence_dpe, axis=1)\n",
    "conso_moyenne_bat['classe_reelle'] = conso_moyenne_bat['conso_par_m2_an_moy'].apply(trouver_classe_reelle)\n",
    "\n",
    "# Résultats\n",
    "print(\"=== Cohérence DPE / Consommation réelle ===\")\n",
    "print(conso_moyenne_bat['coherence_dpe'].value_counts())\n",
    "print()\n",
    "\n",
    "# Bâtiments incohérents\n",
    "incoherents = conso_moyenne_bat[conso_moyenne_bat['coherence_dpe'] != 'coherent'].copy()\n",
    "incoherents['ecart_classe'] = incoherents.apply(\n",
    "    lambda r: ord(r['classe_reelle']) - ord(r['classe_energetique']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Nombre de bâtiments avec incohérence DPE : {len(incoherents)}\")\n",
    "print()\n",
    "\n",
    "if len(incoherents) > 0:\n",
    "    incoherents_sorted = incoherents.sort_values('ecart_classe', ascending=False)\n",
    "    print(\"=== Bâtiments dont la consommation ne correspond pas au DPE ===\")\n",
    "    display(\n",
    "        incoherents_sorted[[\n",
    "            'batiment_id', 'nom', 'classe_energetique', 'classe_reelle',\n",
    "            'conso_par_m2_an_moy', 'surface_m2', 'coherence_dpe', 'ecart_classe'\n",
    "        ]]\n",
    "    )\n",
    "else:\n",
    "    print(\"Tous les bâtiments sont cohérents avec leur classe DPE.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomalies temporelles\n",
    "\n",
    "Détection de schémas de consommation inhabituels :\n",
    "- Consommation pendant les heures de fermeture connues\n",
    "- Consommation le week-end pour les bâtiments censés être fermés (écoles, mairies)\n",
    "- Bâtiments avec des profils incohérents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Détection d'anomalies temporelles ===\n",
    "\n",
    "df_temp = df.copy()\n",
    "df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "df_temp['jour_num'] = df_temp['timestamp'].dt.dayofweek  # 0=lundi, 6=dimanche\n",
    "df_temp['est_weekend'] = df_temp['jour_num'] >= 5\n",
    "\n",
    "# Types de bâtiments normalement fermés le week-end\n",
    "types_fermes_weekend = ['ecole', 'école', 'mairie', 'college', 'collège',\n",
    "                        'lycee', 'lycée', 'creche', 'crèche', 'bibliotheque',\n",
    "                        'bibliothèque', 'administration']\n",
    "\n",
    "# Identifier les bâtiments censés être fermés le week-end (par type)\n",
    "df_temp['type_lower'] = df_temp['type'].str.lower().str.strip()\n",
    "df_temp['devrait_fermer_weekend'] = df_temp['type_lower'].isin(types_fermes_weekend)\n",
    "\n",
    "# Calculer la consommation moyenne en semaine vs week-end par bâtiment\n",
    "conso_semaine = (\n",
    "    df_temp[~df_temp['est_weekend']]\n",
    "    .groupby(['batiment_id', 'nom', 'type'])['consommation']\n",
    "    .mean()\n",
    "    .reset_index(name='conso_moy_semaine')\n",
    ")\n",
    "\n",
    "conso_weekend = (\n",
    "    df_temp[df_temp['est_weekend']]\n",
    "    .groupby(['batiment_id', 'nom', 'type'])['consommation']\n",
    "    .mean()\n",
    "    .reset_index(name='conso_moy_weekend')\n",
    ")\n",
    "\n",
    "comparaison_temporelle = conso_semaine.merge(conso_weekend, on=['batiment_id', 'nom', 'type'], how='inner')\n",
    "comparaison_temporelle['ratio_weekend_semaine'] = (\n",
    "    comparaison_temporelle['conso_moy_weekend'] / comparaison_temporelle['conso_moy_semaine']\n",
    ")\n",
    "\n",
    "# Bâtiments devant être fermés le week-end mais avec forte consommation\n",
    "comparaison_temporelle['type_lower'] = comparaison_temporelle['type'].str.lower().str.strip()\n",
    "comparaison_temporelle['devrait_fermer_weekend'] = (\n",
    "    comparaison_temporelle['type_lower'].isin(types_fermes_weekend)\n",
    ")\n",
    "\n",
    "# Seuil : si la consommation week-end dépasse 50% de celle de la semaine\n",
    "# pour un bâtiment qui devrait être fermé → anomalie\n",
    "anomalies_weekend = comparaison_temporelle[\n",
    "    (comparaison_temporelle['devrait_fermer_weekend']) &\n",
    "    (comparaison_temporelle['ratio_weekend_semaine'] > 0.5)\n",
    "].copy()\n",
    "\n",
    "print(f\"Bâtiments avec consommation week-end suspecte : {len(anomalies_weekend)}\")\n",
    "if len(anomalies_weekend) > 0:\n",
    "    display(\n",
    "        anomalies_weekend[[\n",
    "            'batiment_id', 'nom', 'type', 'conso_moy_semaine',\n",
    "            'conso_moy_weekend', 'ratio_weekend_semaine'\n",
    "        ]].sort_values('ratio_weekend_semaine', ascending=False)\n",
    "    )\n",
    "print()\n",
    "\n",
    "# Détection de consommation nocturne anormale (22h-6h) pour tous les bâtiments\n",
    "df_temp['est_nuit'] = (df_temp['heure'] >= 22) | (df_temp['heure'] < 6)\n",
    "\n",
    "conso_jour = (\n",
    "    df_temp[~df_temp['est_nuit']]\n",
    "    .groupby(['batiment_id', 'nom', 'type'])['consommation']\n",
    "    .mean()\n",
    "    .reset_index(name='conso_moy_jour')\n",
    ")\n",
    "\n",
    "conso_nuit = (\n",
    "    df_temp[df_temp['est_nuit']]\n",
    "    .groupby(['batiment_id', 'nom', 'type'])['consommation']\n",
    "    .mean()\n",
    "    .reset_index(name='conso_moy_nuit')\n",
    ")\n",
    "\n",
    "comparaison_nuit = conso_jour.merge(conso_nuit, on=['batiment_id', 'nom', 'type'], how='inner')\n",
    "comparaison_nuit['ratio_nuit_jour'] = (\n",
    "    comparaison_nuit['conso_moy_nuit'] / comparaison_nuit['conso_moy_jour']\n",
    ")\n",
    "\n",
    "# Bâtiments avec consommation nocturne excessive (>70% de la journée)\n",
    "anomalies_nuit = comparaison_nuit[comparaison_nuit['ratio_nuit_jour'] > 0.7].copy()\n",
    "\n",
    "print(f\"Bâtiments avec consommation nocturne anormalement élevée : {len(anomalies_nuit)}\")\n",
    "if len(anomalies_nuit) > 0:\n",
    "    display(\n",
    "        anomalies_nuit[[\n",
    "            'batiment_id', 'nom', 'type', 'conso_moy_jour',\n",
    "            'conso_moy_nuit', 'ratio_nuit_jour'\n",
    "        ]].sort_values('ratio_nuit_jour', ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score d'anomalie global par bâtiment\n",
    "\n",
    "Construction d'un score composite basé sur :\n",
    "- Nombre de pics de consommation (3σ)\n",
    "- Nombre d'outliers IQR\n",
    "- Incohérence DPE\n",
    "- Anomalies temporelles (week-end, nuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construction du score d'anomalie global par bâtiment ===\n",
    "\n",
    "# Base : liste de tous les bâtiments\n",
    "batiments = df[['batiment_id', 'nom', 'type', 'commune', 'surface_m2', 'classe_energetique']].drop_duplicates()\n",
    "\n",
    "# 1. Score pics 3-sigma (normalisé)\n",
    "score_3sigma = anomalies_par_batiment_3sigma.copy()\n",
    "if len(score_3sigma) > 0 and score_3sigma['nb_anomalies_3sigma'].max() > 0:\n",
    "    score_3sigma['score_3sigma'] = (\n",
    "        score_3sigma['nb_anomalies_3sigma'] / score_3sigma['nb_anomalies_3sigma'].max() * 25\n",
    "    )\n",
    "else:\n",
    "    score_3sigma['score_3sigma'] = 0\n",
    "\n",
    "# 2. Score outliers IQR (normalisé)\n",
    "score_iqr = outliers_par_batiment_iqr.copy()\n",
    "if len(score_iqr) > 0 and score_iqr['nb_outliers_iqr'].max() > 0:\n",
    "    score_iqr['score_iqr'] = (\n",
    "        score_iqr['nb_outliers_iqr'] / score_iqr['nb_outliers_iqr'].max() * 25\n",
    "    )\n",
    "else:\n",
    "    score_iqr['score_iqr'] = 0\n",
    "\n",
    "# 3. Score incohérence DPE\n",
    "score_dpe = conso_moyenne_bat[['batiment_id', 'nom', 'coherence_dpe']].copy()\n",
    "score_dpe['score_dpe'] = score_dpe['coherence_dpe'].map({\n",
    "    'coherent': 0,\n",
    "    'sous_classe': 10,\n",
    "    'sur_classe': 25,\n",
    "    'classe_inconnue': 5\n",
    "})\n",
    "\n",
    "# 4. Score anomalies temporelles\n",
    "score_weekend = anomalies_weekend[['batiment_id', 'nom', 'ratio_weekend_semaine']].copy() if len(anomalies_weekend) > 0 else pd.DataFrame(columns=['batiment_id', 'nom', 'ratio_weekend_semaine'])\n",
    "score_weekend['score_weekend'] = np.minimum(score_weekend['ratio_weekend_semaine'] * 25, 25) if len(score_weekend) > 0 else 0\n",
    "\n",
    "score_nuit_df = anomalies_nuit[['batiment_id', 'nom', 'ratio_nuit_jour']].copy() if len(anomalies_nuit) > 0 else pd.DataFrame(columns=['batiment_id', 'nom', 'ratio_nuit_jour'])\n",
    "score_nuit_df['score_nuit'] = np.minimum(score_nuit_df['ratio_nuit_jour'] * 15, 15) if len(score_nuit_df) > 0 else 0\n",
    "\n",
    "# Assemblage du score global\n",
    "score_global = batiments.copy()\n",
    "\n",
    "# Joindre les différents scores\n",
    "score_global = score_global.merge(\n",
    "    score_3sigma[['batiment_id', 'score_3sigma']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "score_global = score_global.merge(\n",
    "    score_iqr[['batiment_id', 'score_iqr']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "score_global = score_global.merge(\n",
    "    score_dpe[['batiment_id', 'score_dpe']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "score_global = score_global.merge(\n",
    "    score_weekend[['batiment_id', 'score_weekend']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "score_global = score_global.merge(\n",
    "    score_nuit_df[['batiment_id', 'score_nuit']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "\n",
    "# Remplir les valeurs manquantes par 0\n",
    "cols_score = ['score_3sigma', 'score_iqr', 'score_dpe', 'score_weekend', 'score_nuit']\n",
    "score_global[cols_score] = score_global[cols_score].fillna(0)\n",
    "\n",
    "# Score total (max théorique = 100)\n",
    "score_global['score_anomalie'] = score_global[cols_score].sum(axis=1).round(1)\n",
    "\n",
    "# Classification par niveau de risque\n",
    "def classifier_risque(score):\n",
    "    \"\"\"Classe le niveau de risque en fonction du score d'anomalie.\"\"\"\n",
    "    if score >= 60:\n",
    "        return 'CRITIQUE'\n",
    "    elif score >= 40:\n",
    "        return 'ELEVE'\n",
    "    elif score >= 20:\n",
    "        return 'MOYEN'\n",
    "    elif score >= 5:\n",
    "        return 'FAIBLE'\n",
    "    else:\n",
    "        return 'NORMAL'\n",
    "\n",
    "score_global['niveau_risque'] = score_global['score_anomalie'].apply(classifier_risque)\n",
    "\n",
    "# Classement\n",
    "score_global = score_global.sort_values('score_anomalie', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=== Score d'anomalie global par bâtiment ===\")\n",
    "print(f\"\\nRépartition par niveau de risque :\")\n",
    "print(score_global['niveau_risque'].value_counts())\n",
    "print()\n",
    "\n",
    "display(\n",
    "    score_global[[\n",
    "        'batiment_id', 'nom', 'type', 'commune', 'surface_m2',\n",
    "        'classe_energetique', 'score_3sigma', 'score_iqr', 'score_dpe',\n",
    "        'score_weekend', 'score_nuit', 'score_anomalie', 'niveau_risque'\n",
    "    ]].head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Liste des bâtiments nécessitant un audit énergétique\n",
    "\n",
    "Priorisation des bâtiments pour un audit en fonction du score d'anomalie,  \n",
    "de l'incohérence DPE et du niveau de consommation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Liste priorisée des bâtiments nécessitant un audit énergétique ===\n",
    "\n",
    "# Enrichir avec la consommation moyenne par m²\n",
    "audit_list = score_global.merge(\n",
    "    conso_moyenne_bat[['batiment_id', 'conso_par_m2_an_moy', 'classe_reelle']],\n",
    "    on='batiment_id', how='left'\n",
    ")\n",
    "\n",
    "# Générer des recommandations personnalisées pour chaque bâtiment\n",
    "def generer_recommandation(row):\n",
    "    \"\"\"Génère une recommandation d'audit personnalisée.\"\"\"\n",
    "    recommandations = []\n",
    "    \n",
    "    if row['score_dpe'] >= 20:\n",
    "        recommandations.append(\n",
    "            f\"Reclassification DPE urgente : classe déclarée {row['classe_energetique']}, \"\n",
    "            f\"classe réelle estimée {row.get('classe_reelle', 'N/A')}\"\n",
    "        )\n",
    "    \n",
    "    if row['score_3sigma'] >= 15:\n",
    "        recommandations.append(\n",
    "            \"Vérification des équipements : pics de consommation fréquents détectés\"\n",
    "        )\n",
    "    \n",
    "    if row['score_weekend'] >= 10:\n",
    "        recommandations.append(\n",
    "            \"Audit de la programmation horaire : consommation week-end anormale\"\n",
    "        )\n",
    "    \n",
    "    if row['score_nuit'] >= 8:\n",
    "        recommandations.append(\n",
    "            \"Contrôle de l'éclairage et du chauffage nocturne : consommation de nuit excessive\"\n",
    "        )\n",
    "    \n",
    "    if row['score_iqr'] >= 15:\n",
    "        recommandations.append(\n",
    "            \"Analyse approfondie du profil de consommation : nombreuses valeurs aberrantes\"\n",
    "        )\n",
    "    \n",
    "    if not recommandations:\n",
    "        recommandations.append(\"Audit de routine recommandé\")\n",
    "    \n",
    "    return ' | '.join(recommandations)\n",
    "\n",
    "audit_list['recommandation'] = audit_list.apply(generer_recommandation, axis=1)\n",
    "\n",
    "# Définir la priorité d'audit\n",
    "def definir_priorite(row):\n",
    "    \"\"\"Définit la priorité d'audit selon le score et les caractéristiques.\"\"\"\n",
    "    if row['niveau_risque'] == 'CRITIQUE':\n",
    "        return 1  # Priorité maximale\n",
    "    elif row['niveau_risque'] == 'ELEVE':\n",
    "        return 2\n",
    "    elif row['niveau_risque'] == 'MOYEN' and row['score_dpe'] > 0:\n",
    "        return 2  # Rehaussé si incohérence DPE\n",
    "    elif row['niveau_risque'] == 'MOYEN':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "audit_list['priorite_audit'] = audit_list.apply(definir_priorite, axis=1)\n",
    "\n",
    "# Filtrer les bâtiments nécessitant un audit (score > 5)\n",
    "audit_necessaire = audit_list[audit_list['score_anomalie'] >= 5].sort_values(\n",
    "    ['priorite_audit', 'score_anomalie'],\n",
    "    ascending=[True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"=== Bâtiments nécessitant un audit énergétique : {len(audit_necessaire)} ===\")\n",
    "print(f\"\\nRépartition par priorité :\")\n",
    "print(audit_necessaire['priorite_audit'].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "# Affichage détaillé\n",
    "colonnes_affichage = [\n",
    "    'priorite_audit', 'batiment_id', 'nom', 'type', 'commune',\n",
    "    'classe_energetique', 'conso_par_m2_an_moy', 'score_anomalie',\n",
    "    'niveau_risque', 'recommandation'\n",
    "]\n",
    "colonnes_disponibles = [c for c in colonnes_affichage if c in audit_necessaire.columns]\n",
    "display(audit_necessaire[colonnes_disponibles])\n",
    "\n",
    "print(f\"\\n--- Priorité 1 (Critique) : {len(audit_necessaire[audit_necessaire['priorite_audit'] == 1])} bâtiments\")\n",
    "print(f\"--- Priorité 2 (Élevée)   : {len(audit_necessaire[audit_necessaire['priorite_audit'] == 2])} bâtiments\")\n",
    "print(f\"--- Priorité 3 (Moyenne)   : {len(audit_necessaire[audit_necessaire['priorite_audit'] == 3])} bâtiments\")\n",
    "print(f\"--- Priorité 4 (Faible)    : {len(audit_necessaire[audit_necessaire['priorite_audit'] == 4])} bâtiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export des anomalies\n",
    "\n",
    "Sauvegarde de toutes les anomalies détectées dans un fichier CSV structuré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Export des anomalies détectées ===\n",
    "\n",
    "anomalies_export = []\n",
    "\n",
    "# 1. Anomalies 3-sigma (pics de consommation)\n",
    "for _, row in anomalies_3sigma.iterrows():\n",
    "    anomalies_export.append({\n",
    "        'batiment_id': row['batiment_id'],\n",
    "        'nom': row['nom'],\n",
    "        'type_anomalie': 'pic_consommation_3sigma',\n",
    "        'description': (\n",
    "            f\"Consommation de {row['consommation']:.1f} kWh détectée le {row['timestamp']} \"\n",
    "            f\"({row['type_energie']}), soit {row['ecart_relatif']:.1f} écarts-types au-dessus de la moyenne\"\n",
    "        ),\n",
    "        'severite': 'haute' if row['ecart_relatif'] > 5 else 'moyenne',\n",
    "        'recommandation': 'Vérifier les équipements et la régulation du bâtiment'\n",
    "    })\n",
    "\n",
    "# 2. Incohérences DPE\n",
    "if len(incoherents) > 0:\n",
    "    for _, row in incoherents.iterrows():\n",
    "        severite = 'haute' if abs(row['ecart_classe']) >= 2 else 'moyenne'\n",
    "        anomalies_export.append({\n",
    "            'batiment_id': row['batiment_id'],\n",
    "            'nom': row['nom'],\n",
    "            'type_anomalie': 'incoherence_dpe',\n",
    "            'description': (\n",
    "                f\"Classe DPE déclarée : {row['classe_energetique']}, \"\n",
    "                f\"classe réelle estimée : {row['classe_reelle']} \"\n",
    "                f\"(consommation réelle : {row['conso_par_m2_an_moy']:.0f} kWh/m²/an)\"\n",
    "            ),\n",
    "            'severite': severite,\n",
    "            'recommandation': 'Reclassification DPE et audit énergétique complet'\n",
    "        })\n",
    "\n",
    "# 3. Anomalies week-end\n",
    "if len(anomalies_weekend) > 0:\n",
    "    for _, row in anomalies_weekend.iterrows():\n",
    "        anomalies_export.append({\n",
    "            'batiment_id': row['batiment_id'],\n",
    "            'nom': row['nom'],\n",
    "            'type_anomalie': 'consommation_weekend_suspecte',\n",
    "            'description': (\n",
    "                f\"Consommation week-end = {row['ratio_weekend_semaine']*100:.0f}% \"\n",
    "                f\"de la consommation en semaine pour un bâtiment de type '{row['type']}'\"\n",
    "            ),\n",
    "            'severite': 'haute' if row['ratio_weekend_semaine'] > 0.8 else 'moyenne',\n",
    "            'recommandation': 'Vérifier la programmation horaire et les équipements en veille'\n",
    "        })\n",
    "\n",
    "# 4. Anomalies nocturnes\n",
    "if len(anomalies_nuit) > 0:\n",
    "    for _, row in anomalies_nuit.iterrows():\n",
    "        anomalies_export.append({\n",
    "            'batiment_id': row['batiment_id'],\n",
    "            'nom': row['nom'],\n",
    "            'type_anomalie': 'consommation_nocturne_excessive',\n",
    "            'description': (\n",
    "                f\"Consommation nocturne = {row['ratio_nuit_jour']*100:.0f}% \"\n",
    "                f\"de la consommation diurne\"\n",
    "            ),\n",
    "            'severite': 'haute' if row['ratio_nuit_jour'] > 0.9 else 'moyenne',\n",
    "            'recommandation': 'Contrôler éclairage, chauffage et équipements actifs la nuit'\n",
    "        })\n",
    "\n",
    "# 5. Sous-consommation suspecte (périodes prolongées)\n",
    "if len(df_periodes_zero) > 0:\n",
    "    for _, row in df_periodes_zero.iterrows():\n",
    "        anomalies_export.append({\n",
    "            'batiment_id': row['batiment_id'],\n",
    "            'nom': row['nom'],\n",
    "            'type_anomalie': 'sous_consommation_prolongee',\n",
    "            'description': (\n",
    "                f\"Quasi-zéro consommation ({row['type_energie']}) pendant {row['duree_heures']}h \"\n",
    "                f\"du {row['debut']} au {row['fin']}\"\n",
    "            ),\n",
    "            'severite': 'haute' if row['duree_heures'] > 72 else 'moyenne',\n",
    "            'recommandation': 'Vérifier le compteur et les raisons de la fermeture éventuelle'\n",
    "        })\n",
    "\n",
    "# Création du DataFrame d'export\n",
    "df_anomalies = pd.DataFrame(anomalies_export)\n",
    "\n",
    "if len(df_anomalies) > 0:\n",
    "    # Ordonner par sévérité puis par bâtiment\n",
    "    ordre_severite = {'haute': 0, 'moyenne': 1, 'basse': 2}\n",
    "    df_anomalies['ordre_sev'] = df_anomalies['severite'].map(ordre_severite)\n",
    "    df_anomalies = df_anomalies.sort_values(['ordre_sev', 'batiment_id']).drop(columns='ordre_sev')\n",
    "    df_anomalies = df_anomalies.reset_index(drop=True)\n",
    "\n",
    "# Sauvegarde en CSV\n",
    "chemin_export = '../output/anomalies_detectees.csv'\n",
    "df_anomalies.to_csv(chemin_export, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Fichier exporté : {chemin_export}\")\n",
    "print(f\"Nombre total d'anomalies exportées : {len(df_anomalies)}\")\n",
    "print()\n",
    "\n",
    "# Statistiques récapitulatives\n",
    "print(\"=== Résumé des anomalies détectées ===\")\n",
    "print(f\"\\nPar type d'anomalie :\")\n",
    "if len(df_anomalies) > 0:\n",
    "    print(df_anomalies['type_anomalie'].value_counts().to_string())\n",
    "    print(f\"\\nPar sévérité :\")\n",
    "    print(df_anomalies['severite'].value_counts().to_string())\n",
    "    print(f\"\\nNombre de bâtiments concernés : {df_anomalies['batiment_id'].nunique()}\")\n",
    "else:\n",
    "    print(\"Aucune anomalie détectée.\")\n",
    "\n",
    "print(\"\\n=== Aperçu du fichier exporté ===\")\n",
    "display(df_anomalies.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapport de recommandations d'audit\n",
    "\n",
    "### Synthèse des résultats\n",
    "\n",
    "L'analyse de détection d'anomalies a identifié plusieurs catégories de problèmes dans les données de consommation énergétique des bâtiments publics :\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Bâtiments prioritaires pour un audit (Priorité 1 - CRITIQUE)\n",
    "\n",
    "Ces bâtiments présentent des anomalies multiples et sévères nécessitant une intervention **immédiate** :\n",
    "- Pics de consommation récurrents dépassant 3 écarts-types\n",
    "- Forte incohérence entre la classe DPE déclarée et la consommation réelle\n",
    "- Consommation anormale pendant les heures de fermeture\n",
    "\n",
    "**Action recommandée** : Audit énergétique complet dans les 3 mois\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Bâtiments sous surveillance (Priorité 2 - ÉLEVÉE)\n",
    "\n",
    "Ces bâtiments montrent des signes significatifs d'inefficacité ou d'anomalies :\n",
    "- Consommation week-end supérieure à 50% de la consommation en semaine\n",
    "- Écart notable entre DPE déclaré et consommation mesurée\n",
    "- Profils de consommation nocturne inhabituels\n",
    "\n",
    "**Action recommandée** : Audit ciblé dans les 6 mois, vérification de la programmation horaire\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Bâtiments à surveiller (Priorité 3 - MOYENNE)\n",
    "\n",
    "Ces bâtiments présentent des anomalies ponctuelles ou modérées :\n",
    "- Quelques pics de consommation isolés\n",
    "- Légère incohérence DPE\n",
    "\n",
    "**Action recommandée** : Surveillance renforcée, audit de routine dans l'année\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Recommandations transversales\n",
    "\n",
    "| Domaine | Recommandation |\n",
    "|---------|---------------|\n",
    "| **Compteurs** | Vérifier l'étalonnage des compteurs pour les bâtiments avec sous-consommation prolongée |\n",
    "| **Programmation** | Auditer les systèmes de gestion technique (GTC/GTB) pour les bâtiments avec consommation hors horaires |\n",
    "| **DPE** | Lancer une campagne de reclassification DPE pour les bâtiments identifiés comme incohérents |\n",
    "| **Équipements** | Inspecter les équipements (chauffage, climatisation) des bâtiments avec pics récurrents |\n",
    "| **Suivi** | Mettre en place un tableau de bord de suivi continu avec alertes automatiques |\n",
    "\n",
    "---\n",
    "\n",
    "### Fichiers générés\n",
    "\n",
    "- `../output/anomalies_detectees.csv` : Liste détaillée de toutes les anomalies avec recommandations\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport généré automatiquement — ECF Data Engineer — Analyse énergétique des bâtiments publics*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}