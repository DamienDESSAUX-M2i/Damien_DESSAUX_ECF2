{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1.1 - Exploration initiale avec PySpark\n",
    "\n",
    "**ECF - Titre Professionnel Data Engineer (RNCP35288)**\n",
    "\n",
    "---\n",
    "\n",
    "## Contexte\n",
    "\n",
    "Ce notebook constitue la premiere etape de notre pipeline de traitement des donnees de consommation energetique\n",
    "de batiments. L'objectif est d'explorer le jeu de donnees brut (`consommations_raw.csv`, environ 7,7 millions de lignes)\n",
    "afin de comprendre sa structure, identifier les problemes de qualite et preparer les etapes de nettoyage ulterieures.\n",
    "\n",
    "Le fichier de reference `batiments.csv` contient les informations descriptives de 146 batiments\n",
    "(type, commune, surface, classe energetique, etc.).\n",
    "\n",
    "### Objectifs de ce notebook\n",
    "\n",
    "1. Charger les donnees brutes avec PySpark et analyser le schema infere\n",
    "2. Calculer des statistiques descriptives par type d'energie\n",
    "3. Identifier et quantifier systematiquement les defauts de qualite\n",
    "4. Analyser la repartition des mesures par batiment\n",
    "5. Produire un rapport d'audit complet de la qualite des donnees\n",
    "\n",
    "### Defauts attendus dans les donnees\n",
    "\n",
    "- Formats de dates multiples (ISO, FR dd/mm/yyyy, US mm/dd/yyyy, ISO avec T)\n",
    "- Valeurs negatives (~0,5%)\n",
    "- Pics aberrants / outliers >15000 (~1%)\n",
    "- Doublons (~2%)\n",
    "- Separateurs decimaux mixtes (virgule au lieu de point, ~12%)\n",
    "- Valeurs textuelles dans le champ consommation (\"erreur\", \"N/A\", \"---\", \"null\" - ~1,5%)\n",
    "- Periodes de donnees manquantes (~1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "26/02/11 18:22:24 WARN Utils: Your hostname, MacBook-Pro-de-Ihab.local, resolves to a loopback address: 127.0.0.1; using 172.20.10.5 instead (on interface en0)\n",
      "26/02/11 18:22:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/11 18:22:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version de Spark : 4.1.1\n",
      "Session Spark initialisee avec succes.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports et creation de la session Spark\n",
    "# =============================================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "# Creation de la session Spark configuree pour le traitement local\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ECF Energie - Exploration initiale\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reduction du niveau de log pour plus de lisibilite\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Version de Spark : {spark.version}\")\n",
    "print(f\"Session Spark initialisee avec succes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des donnees de consommation\n",
    "\n",
    "Nous chargeons le fichier `consommations_raw.csv` avec l'inference automatique du schema par PySpark.\n",
    "Le fichier contient environ 7,7 millions de lignes avec les colonnes :\n",
    "- `batiment_id` : identifiant unique du batiment\n",
    "- `timestamp` : horodatage de la mesure\n",
    "- `type_energie` : type d'energie (electricite, gaz, etc.)\n",
    "- `consommation` : valeur de consommation mesuree\n",
    "- `unite` : unite de mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemin des consommations : /Users/ihababadi/Downloads/ECF_ENERGIE_BATIMENTS (1)/ecf_energie/data/consommations_raw.csv\n",
      "Chemin des batiments     : /Users/ihababadi/Downloads/ECF_ENERGIE_BATIMENTS (1)/ecf_energie/data/batiments.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SCHEMA INFERE PAR PYSPARK\n",
      "============================================================\n",
      "root\n",
      " |-- batiment_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- type_energie: string (nullable = true)\n",
      " |-- consommation: string (nullable = true)\n",
      " |-- unite: string (nullable = true)\n",
      "\n",
      "\n",
      "============================================================\n",
      "APERCU DES 10 PREMIERES LIGNES\n",
      "============================================================\n",
      "+-----------+-------------------+------------+------------+-----+\n",
      "|batiment_id|timestamp          |type_energie|consommation|unite|\n",
      "+-----------+-------------------+------------+------------+-----+\n",
      "|BAT0141    |2023-12-21 13:00:00|gaz         |342.34      |kWh  |\n",
      "|BAT0080    |08/08/2023 13:00   |gaz         |1256.73     |kWh  |\n",
      "|BAT0122    |06/13/2024 11:00:00|eau         |133.57      |m3   |\n",
      "|BAT0033    |2023-06-25 00:00:00|eau         |0.23        |m3   |\n",
      "|BAT0064    |11/29/2024 04:00:00|gaz         |12.26       |kWh  |\n",
      "|BAT0052    |09/15/2024 18:00:00|gaz         |701.01      |kWh  |\n",
      "|BAT0097    |2024-01-25 12:00:00|gaz         |444.87      |kWh  |\n",
      "|BAT0073    |27/03/2023 13:00   |electricite |123.97      |kWh  |\n",
      "|BAT0084    |03/12/2024 17:00:00|eau         |17.88       |m3   |\n",
      "|BAT0022    |2024-10-30 03:00:00|eau         |0.80        |m3   |\n",
      "+-----------+-------------------+------------+------------+-----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Chargement du fichier de consommations brutes\n",
    "# =============================================================================\n",
    "\n",
    "# Chemin vers les donnees (relatif au dossier notebooks)\n",
    "DATA_DIR = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"..\", \"data\")\n",
    "CONSOMMATIONS_PATH = os.path.join(DATA_DIR, \"consommations_raw.csv\")\n",
    "BATIMENTS_PATH = os.path.join(DATA_DIR, \"batiments.csv\")\n",
    "\n",
    "print(f\"Chemin des consommations : {os.path.abspath(CONSOMMATIONS_PATH)}\")\n",
    "print(f\"Chemin des batiments     : {os.path.abspath(BATIMENTS_PATH)}\")\n",
    "\n",
    "# Chargement avec inference de schema automatique\n",
    "# header=True pour utiliser la premiere ligne comme noms de colonnes\n",
    "df_conso = spark.read.csv(\n",
    "    CONSOMMATIONS_PATH,\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\"\n",
    ")\n",
    "\n",
    "# Affichage du schema infere\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCHEMA INFERE PAR PYSPARK\")\n",
    "print(\"=\"*60)\n",
    "df_conso.printSchema()\n",
    "\n",
    "# Affichage des 10 premieres lignes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APERCU DES 10 PREMIERES LIGNES\")\n",
    "print(\"=\"*60)\n",
    "df_conso.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse du schema infere et problemes de typage\n",
    "\n",
    "L'inference automatique de PySpark peut poser des problemes lorsque les donnees contiennent\n",
    "des valeurs heterogenes. En particulier, la colonne `consommation` risque d'etre inferee comme\n",
    "`string` au lieu de `double` en raison de :\n",
    "- La presence de valeurs textuelles (\"erreur\", \"N/A\", \"---\", \"null\")\n",
    "- L'utilisation de la virgule comme separateur decimal dans certaines lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de lignes : 7,758,868\n",
      "Nombre de colonnes     : 5\n",
      "Colonnes               : ['batiment_id', 'timestamp', 'type_energie', 'consommation', 'unite']\n",
      "\n",
      "============================================================\n",
      "TYPES DES COLONNES\n",
      "============================================================\n",
      "  batiment_id               -> string\n",
      "  timestamp                 -> string\n",
      "  type_energie              -> string\n",
      "  consommation              -> string <-- ATTENTION : devrait etre numeric\n",
      "  unite                     -> string\n",
      "\n",
      "============================================================\n",
      "VALEURS DISTINCTES DE 'type_energie'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|type_energie|\n",
      "+------------+\n",
      "|eau         |\n",
      "|electricite |\n",
      "|gaz         |\n",
      "+------------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "VALEURS DISTINCTES DE 'unite'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|unite|\n",
      "+-----+\n",
      "|kWh  |\n",
      "|m3   |\n",
      "+-----+\n",
      "\n",
      "\n",
      "============================================================\n",
      "EXEMPLES DE VALEURS PROBLEMATIQUES DANS 'consommation'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|20,38       |\n",
      "|19,14       |\n",
      "|1,28        |\n",
      "|1148,56     |\n",
      "|12,83       |\n",
      "|12,33       |\n",
      "|206,03      |\n",
      "|47,60       |\n",
      "|23,54       |\n",
      "|9,37        |\n",
      "+------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|null        |\n",
      "|N/A         |\n",
      "|erreur      |\n",
      "|---         |\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Analyse detaillee du schema et des types de donnees\n",
    "# =============================================================================\n",
    "\n",
    "# Nombre total de lignes\n",
    "nb_total = df_conso.count()\n",
    "print(f\"Nombre total de lignes : {nb_total:,}\")\n",
    "print(f\"Nombre de colonnes     : {len(df_conso.columns)}\")\n",
    "print(f\"Colonnes               : {df_conso.columns}\")\n",
    "\n",
    "# Verification du type de la colonne consommation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TYPES DES COLONNES\")\n",
    "print(\"=\"*60)\n",
    "for col_name, col_type in df_conso.dtypes:\n",
    "    indicateur = \" <-- ATTENTION : devrait etre numeric\" if col_name == \"consommation\" and col_type == \"string\" else \"\"\n",
    "    print(f\"  {col_name:25s} -> {col_type}{indicateur}\")\n",
    "\n",
    "# Valeurs distinctes de type_energie\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALEURS DISTINCTES DE 'type_energie'\")\n",
    "print(\"=\"*60)\n",
    "df_conso.select(\"type_energie\").distinct().orderBy(\"type_energie\").show(truncate=False)\n",
    "\n",
    "# Valeurs distinctes de unite\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALEURS DISTINCTES DE 'unite'\")\n",
    "print(\"=\"*60)\n",
    "df_conso.select(\"unite\").distinct().orderBy(\"unite\").show(truncate=False)\n",
    "\n",
    "# Echantillon de valeurs non-numeriques dans la colonne consommation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXEMPLES DE VALEURS PROBLEMATIQUES DANS 'consommation'\")\n",
    "print(\"=\"*60)\n",
    "# Valeurs contenant des virgules (separateur decimal mixte)\n",
    "df_conso.filter(F.col(\"consommation\").contains(\",\")).select(\"consommation\").distinct().show(10, truncate=False)\n",
    "\n",
    "# Valeurs purement textuelles\n",
    "df_conso.filter(\n",
    "    ~F.col(\"consommation\").rlike(r\"^-?[0-9]+([\\.\\,][0-9]+)?$\")\n",
    ").select(\"consommation\").distinct().show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistiques descriptives par type d'energie\n",
    "\n",
    "Pour calculer les statistiques numeriques, nous devons d'abord filtrer les valeurs textuelles\n",
    "et convertir les virgules en points dans le champ `consommation`, puis caster en `double`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lignes avec valeur numerique valide : 7,719,893 / 7,758,868\n",
      "\n",
      "============================================================\n",
      "STATISTIQUES DESCRIPTIVES PAR TYPE D'ENERGIE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-------+----------+--------+--------+-----+-------+------+\n",
      "|type_energie|nb_mesures|moyenne|ecart_type|minimum |maximum |Q1   |mediane|Q3    |\n",
      "+------------+----------+-------+----------+--------+--------+-----+-------+------+\n",
      "|eau         |2573156   |204.36 |2398.57   |-657.01 |49999.23|1.72 |7.52   |22.87 |\n",
      "|electricite |2573364   |430.64 |2429.51   |-4003.35|49999.13|29.33|108.53 |306.34|\n",
      "|gaz         |2573373   |560.94 |2465.81   |-5963.49|49999.49|43.63|160.57 |454.62|\n",
      "+------------+----------+-------+----------+--------+--------+-----+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Statistiques descriptives par type d'energie\n",
    "# =============================================================================\n",
    "\n",
    "# Preparation : filtrer les valeurs textuelles et convertir les virgules en points\n",
    "df_conso_num = df_conso.filter(\n",
    "    # On ne garde que les lignes dont la consommation ressemble a un nombre\n",
    "    F.col(\"consommation\").rlike(r\"^-?[0-9]+([\\.\\,][0-9]+)?$\")\n",
    ").withColumn(\n",
    "    # Remplacement de la virgule par un point pour les separateurs decimaux\n",
    "    \"consommation_clean\",\n",
    "    F.regexp_replace(F.col(\"consommation\"), \",\", \".\").cast(DoubleType())\n",
    ")\n",
    "\n",
    "print(f\"Lignes avec valeur numerique valide : {df_conso_num.count():,} / {nb_total:,}\")\n",
    "\n",
    "# Statistiques descriptives par type d'energie\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTIQUES DESCRIPTIVES PAR TYPE D'ENERGIE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "stats_par_energie = df_conso_num.groupBy(\"type_energie\").agg(\n",
    "    F.count(\"consommation_clean\").alias(\"nb_mesures\"),\n",
    "    F.round(F.mean(\"consommation_clean\"), 2).alias(\"moyenne\"),\n",
    "    F.round(F.stddev(\"consommation_clean\"), 2).alias(\"ecart_type\"),\n",
    "    F.round(F.min(\"consommation_clean\"), 2).alias(\"minimum\"),\n",
    "    F.round(F.max(\"consommation_clean\"), 2).alias(\"maximum\"),\n",
    "    F.round(F.expr(\"percentile_approx(consommation_clean, 0.25)\"), 2).alias(\"Q1\"),\n",
    "    F.round(F.expr(\"percentile_approx(consommation_clean, 0.50)\"), 2).alias(\"mediane\"),\n",
    "    F.round(F.expr(\"percentile_approx(consommation_clean, 0.75)\"), 2).alias(\"Q3\")\n",
    ").orderBy(\"type_energie\")\n",
    "\n",
    "stats_par_energie.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identification des problemes de qualite\n",
    "\n",
    "Nous allons systematiquement identifier et quantifier chaque type de defaut present\n",
    "dans le jeu de donnees :\n",
    "\n",
    "1. **Valeurs textuelles** : lignes ou `consommation` n'est pas un nombre\n",
    "2. **Valeurs negatives** : consommations < 0\n",
    "3. **Valeurs aberrantes (outliers)** : consommations > 10 000\n",
    "4. **Doublons** : lignes strictement identiques\n",
    "5. **Separateurs decimaux mixtes** : utilisation de la virgule au lieu du point\n",
    "6. **Formats de dates multiples** : ISO, FR, US, ISO avec T\n",
    "7. **Periodes manquantes** : gaps temporels dans les series de mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AUDIT DE QUALITE DES DONNEES - IDENTIFICATION DES DEFAUTS\n",
      "======================================================================\n",
      "\n",
      "Nombre total de lignes : 7,758,868\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "1. VALEURS TEXTUELLES (non-numeriques) dans 'consommation'\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre : 38,975 (0.50%)\n",
      "  Valeurs distinctes trouvees :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|null        |\n",
      "|N/A         |\n",
      "|erreur      |\n",
      "|---         |\n",
      "+------------+\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "2. VALEURS NEGATIVES\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre : 38,910 (0.50%)\n",
      "  Exemples :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------+------------------+\n",
      "|batiment_id|timestamp          |type_energie|consommation_clean|\n",
      "+-----------+-------------------+------------+------------------+\n",
      "|BAT0005    |2023-11-21T15:00:00|gaz         |-5963.49          |\n",
      "|BAT0005    |03/11/2024 09:00   |gaz         |-5668.83          |\n",
      "|BAT0005    |03/11/2024 09:00   |gaz         |-5668.83          |\n",
      "|BAT0048    |06/11/2024 16:00   |gaz         |-5457.98          |\n",
      "|BAT0005    |2023-11-14T10:00:00|gaz         |-5200.34          |\n",
      "+-----------+-------------------+------------+------------------+\n",
      "only showing top 5 rows\n",
      "----------------------------------------------------------------------\n",
      "3. VALEURS ABERRANTES (outliers > 10 000)\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre : 38,560 (0.50%)\n",
      "  Distribution des outliers :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------------+\n",
      "|min_outlier|max_outlier|moyenne_outliers|\n",
      "+-----------+-----------+----------------+\n",
      "|15003.26   |49999.49   |32591.63        |\n",
      "+-----------+-----------+----------------+\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "4. DOUBLONS (lignes strictement identiques)\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Lignes distinctes : 7,606,734\n",
      "  Doublons          : 152,134 (1.96%)\n",
      "  Exemples de lignes dupliquees :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+------------+------------+-----+-----+\n",
      "|batiment_id|timestamp          |type_energie|consommation|unite|count|\n",
      "+-----------+-------------------+------------+------------+-----+-----+\n",
      "|BAT0122    |2023-08-06 15:00:00|electricite |635.22      |kWh  |2    |\n",
      "|BAT0112    |2023-08-01T12:00:00|eau         |250.60      |m3   |2    |\n",
      "|BAT0064    |11/29/2024 04:00:00|gaz         |12.26       |kWh  |2    |\n",
      "|BAT0113    |2023-11-23T03:00:00|electricite |23.36       |kWh  |2    |\n",
      "|BAT0081    |2024-01-03T19:00:00|electricite |242.69      |kWh  |2    |\n",
      "+-----------+-------------------+------------+------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "----------------------------------------------------------------------\n",
      "5. SEPARATEURS DECIMAUX MIXTES (virgule au lieu de point)\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Nombre : 925,392 (11.93%)\n",
      "  Exemples :\n",
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|10,10       |\n",
      "|72,29       |\n",
      "|17,82       |\n",
      "|0,92        |\n",
      "|290,65      |\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "----------------------------------------------------------------------\n",
      "6. FORMATS DE DATES MULTIPLES\n",
      "----------------------------------------------------------------------\n",
      "  Repartition des formats de dates :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+---------+-----------+\n",
      "|format_date                        |nb_lignes|pourcentage|\n",
      "+-----------------------------------+---------+-----------+\n",
      "|FR ou US (dd/mm/yyyy ou mm/dd/yyyy)|3878001  |49.98      |\n",
      "|ISO avec T (yyyy-MM-ddTHH:mm:ss)   |1941452  |25.02      |\n",
      "|ISO standard (yyyy-MM-dd HH:mm:ss) |1939415  |25.0       |\n",
      "+-----------------------------------+---------+-----------+\n",
      "\n",
      "  Exemples par format :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  >> FR ou US (dd/mm/yyyy ou mm/dd/yyyy) :\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|08/08/2023 13:00   |\n",
      "|06/13/2024 11:00:00|\n",
      "|11/29/2024 04:00:00|\n",
      "+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "  >> ISO avec T (yyyy-MM-ddTHH:mm:ss) :\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2023-12-06T11:00:00|\n",
      "|2024-04-26T10:00:00|\n",
      "|2024-12-18T07:00:00|\n",
      "+-------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "  >> ISO standard (yyyy-MM-dd HH:mm:ss) :\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2023-12-21 13:00:00|\n",
      "|2023-06-25 00:00:00|\n",
      "|2024-01-25 12:00:00|\n",
      "+-------------------+\n",
      "only showing top 3 rows\n",
      "----------------------------------------------------------------------\n",
      "7. PERIODES DE DONNEES MANQUANTES\n",
      "----------------------------------------------------------------------\n",
      "  Valeurs nulles ou vides par colonne :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    batiment_id               : 0 valeurs nulles/vides (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp                 : 0 valeurs nulles/vides (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type_energie              : 0 valeurs nulles/vides (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    consommation              : 0 valeurs nulles/vides (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    unite                     : 0 valeurs nulles/vides (0.00%)\n",
      "\n",
      "  Analyse des gaps temporels (echantillon de 5 batiments) :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batiment BAT0093 : 2023-01-01 -> 2024-12-31 | 731 jours presents / 731 attendus | 0 jours manquants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batiment BAT0047 : 2023-01-01 -> 2024-12-31 | 731 jours presents / 731 attendus | 0 jours manquants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batiment BAT0126 : 2023-01-01 -> 2024-12-31 | 731 jours presents / 731 attendus | 0 jours manquants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batiment BAT0045 : 2023-01-01 -> 2024-12-31 | 731 jours presents / 731 attendus | 0 jours manquants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 134:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batiment BAT0055 : 2023-01-01 -> 2024-12-31 | 731 jours presents / 731 attendus | 0 jours manquants\n",
      "\n",
      "======================================================================\n",
      "RESUME DES DEFAUTS DETECTES\n",
      "======================================================================\n",
      "  Defaut                                            Nombre        %\n",
      "  --------------------------------------------- ---------- --------\n",
      "  Valeurs textuelles                                38,975    0.50%\n",
      "  Valeurs negatives                                 38,910    0.50%\n",
      "  Outliers (> 10 000)                               38,560    0.50%\n",
      "  Doublons                                         152,134    1.96%\n",
      "  Separateurs decimaux mixtes (virgule)            925,392   11.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Identification et quantification des defauts de qualite\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AUDIT DE QUALITE DES DONNEES - IDENTIFICATION DES DEFAUTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nNombre total de lignes : {nb_total:,}\\n\")\n",
    "\n",
    "# --- 1. Valeurs textuelles (non-numeriques) dans consommation ---\n",
    "print(\"-\"*70)\n",
    "print(\"1. VALEURS TEXTUELLES (non-numeriques) dans 'consommation'\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_texte = df_conso.filter(\n",
    "    ~F.col(\"consommation\").rlike(r\"^-?[0-9]+([\\.\\,][0-9]+)?$\")\n",
    ")\n",
    "nb_texte = df_texte.count()\n",
    "pct_texte = (nb_texte / nb_total) * 100\n",
    "\n",
    "print(f\"  Nombre : {nb_texte:,} ({pct_texte:.2f}%)\")\n",
    "print(\"  Valeurs distinctes trouvees :\")\n",
    "df_texte.select(\"consommation\").distinct().show(truncate=False)\n",
    "\n",
    "# --- 2. Valeurs negatives ---\n",
    "print(\"-\"*70)\n",
    "print(\"2. VALEURS NEGATIVES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_negatif = df_conso_num.filter(F.col(\"consommation_clean\") < 0)\n",
    "nb_negatif = df_negatif.count()\n",
    "pct_negatif = (nb_negatif / nb_total) * 100\n",
    "\n",
    "print(f\"  Nombre : {nb_negatif:,} ({pct_negatif:.2f}%)\")\n",
    "print(\"  Exemples :\")\n",
    "df_negatif.select(\"batiment_id\", \"timestamp\", \"type_energie\", \"consommation_clean\") \\\n",
    "    .orderBy(\"consommation_clean\").show(5, truncate=False)\n",
    "\n",
    "# --- 3. Valeurs aberrantes (outliers > 10 000) ---\n",
    "print(\"-\"*70)\n",
    "print(\"3. VALEURS ABERRANTES (outliers > 10 000)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_outliers = df_conso_num.filter(F.col(\"consommation_clean\") > 10000)\n",
    "nb_outliers = df_outliers.count()\n",
    "pct_outliers = (nb_outliers / nb_total) * 100\n",
    "\n",
    "print(f\"  Nombre : {nb_outliers:,} ({pct_outliers:.2f}%)\")\n",
    "print(\"  Distribution des outliers :\")\n",
    "df_outliers.select(\n",
    "    F.round(F.min(\"consommation_clean\"), 2).alias(\"min_outlier\"),\n",
    "    F.round(F.max(\"consommation_clean\"), 2).alias(\"max_outlier\"),\n",
    "    F.round(F.mean(\"consommation_clean\"), 2).alias(\"moyenne_outliers\")\n",
    ").show(truncate=False)\n",
    "\n",
    "# --- 4. Doublons (lignes strictement identiques) ---\n",
    "print(\"-\"*70)\n",
    "print(\"4. DOUBLONS (lignes strictement identiques)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "nb_distincts = df_conso.distinct().count()\n",
    "nb_doublons = nb_total - nb_distincts\n",
    "pct_doublons = (nb_doublons / nb_total) * 100\n",
    "\n",
    "print(f\"  Lignes distinctes : {nb_distincts:,}\")\n",
    "print(f\"  Doublons          : {nb_doublons:,} ({pct_doublons:.2f}%)\")\n",
    "\n",
    "# Exemples de doublons\n",
    "print(\"  Exemples de lignes dupliquees :\")\n",
    "df_conso.groupBy(df_conso.columns).count().filter(F.col(\"count\") > 1) \\\n",
    "    .orderBy(F.col(\"count\").desc()).show(5, truncate=False)\n",
    "\n",
    "# --- 5. Separateurs decimaux mixtes (virgule) ---\n",
    "print(\"-\"*70)\n",
    "print(\"5. SEPARATEURS DECIMAUX MIXTES (virgule au lieu de point)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "df_virgule = df_conso.filter(F.col(\"consommation\").contains(\",\"))\n",
    "nb_virgule = df_virgule.count()\n",
    "pct_virgule = (nb_virgule / nb_total) * 100\n",
    "\n",
    "print(f\"  Nombre : {nb_virgule:,} ({pct_virgule:.2f}%)\")\n",
    "print(\"  Exemples :\")\n",
    "df_virgule.select(\"consommation\").show(5, truncate=False)\n",
    "\n",
    "# --- 6. Formats de dates multiples ---\n",
    "print(\"-\"*70)\n",
    "print(\"6. FORMATS DE DATES MULTIPLES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Detection des differents formats de date\n",
    "df_dates = df_conso.withColumn(\n",
    "    \"format_date\",\n",
    "    F.when(\n",
    "        F.col(\"timestamp\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}\"),\n",
    "        F.lit(\"ISO avec T (yyyy-MM-ddTHH:mm:ss)\")\n",
    "    ).when(\n",
    "        F.col(\"timestamp\").rlike(r\"^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}\"),\n",
    "        F.lit(\"ISO standard (yyyy-MM-dd HH:mm:ss)\")\n",
    "    ).when(\n",
    "        F.col(\"timestamp\").rlike(r\"^\\d{2}/\\d{2}/\\d{4}\"),\n",
    "        F.lit(\"FR ou US (dd/mm/yyyy ou mm/dd/yyyy)\")\n",
    "    ).otherwise(\n",
    "        F.lit(\"Autre / Inconnu\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"  Repartition des formats de dates :\")\n",
    "df_dates.groupBy(\"format_date\").agg(\n",
    "    F.count(\"*\").alias(\"nb_lignes\"),\n",
    "    F.round(F.count(\"*\") / nb_total * 100, 2).alias(\"pourcentage\")\n",
    ").orderBy(F.col(\"nb_lignes\").desc()).show(truncate=False)\n",
    "\n",
    "# Exemples pour chaque format\n",
    "print(\"  Exemples par format :\")\n",
    "for fmt in df_dates.select(\"format_date\").distinct().collect():\n",
    "    print(f\"\\n  >> {fmt['format_date']} :\")\n",
    "    df_dates.filter(F.col(\"format_date\") == fmt[\"format_date\"]) \\\n",
    "        .select(\"timestamp\").show(3, truncate=False)\n",
    "\n",
    "# --- 7. Periodes de donnees manquantes ---\n",
    "print(\"-\"*70)\n",
    "print(\"7. PERIODES DE DONNEES MANQUANTES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# On analyse les valeurs nulles par colonne\n",
    "print(\"  Valeurs nulles ou vides par colonne :\")\n",
    "for col_name in df_conso.columns:\n",
    "    nb_nulls = df_conso.filter(\n",
    "        F.col(col_name).isNull() | (F.trim(F.col(col_name).cast(\"string\")) == \"\")\n",
    "    ).count()\n",
    "    pct_null = (nb_nulls / nb_total) * 100\n",
    "    print(f\"    {col_name:25s} : {nb_nulls:,} valeurs nulles/vides ({pct_null:.2f}%)\")\n",
    "\n",
    "# Detection de gaps temporels (periodes sans mesure)\n",
    "# On prend un echantillon de batiments pour analyser la continuite\n",
    "print(\"\\n  Analyse des gaps temporels (echantillon de 5 batiments) :\")\n",
    "\n",
    "# On filtre les lignes avec des dates au format ISO standard pour cette analyse\n",
    "df_iso = df_conso.filter(\n",
    "    F.col(\"timestamp\").rlike(r\"^\\d{4}-\\d{2}-\\d{2}\")\n",
    ").withColumn(\n",
    "    \"date_parsed\",\n",
    "    F.to_date(F.substring(F.col(\"timestamp\"), 1, 10), \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "# Batiments avec le plus de mesures pour un echantillon representatif\n",
    "top_batiments = df_iso.groupBy(\"batiment_id\").count() \\\n",
    "    .orderBy(F.col(\"count\").desc()).limit(5).select(\"batiment_id\").collect()\n",
    "\n",
    "for row in top_batiments:\n",
    "    bid = row[\"batiment_id\"]\n",
    "    df_bat = df_iso.filter(F.col(\"batiment_id\") == bid)\n",
    "    date_min = df_bat.agg(F.min(\"date_parsed\")).collect()[0][0]\n",
    "    date_max = df_bat.agg(F.max(\"date_parsed\")).collect()[0][0]\n",
    "    nb_jours_distincts = df_bat.select(\"date_parsed\").distinct().count()\n",
    "    if date_min and date_max:\n",
    "        nb_jours_attendus = (date_max - date_min).days + 1\n",
    "        nb_jours_manquants = nb_jours_attendus - nb_jours_distincts\n",
    "        print(f\"    Batiment {bid} : {date_min} -> {date_max} | \"\n",
    "              f\"{nb_jours_distincts} jours presents / {nb_jours_attendus} attendus | \"\n",
    "              f\"{nb_jours_manquants} jours manquants\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUME DES DEFAUTS DETECTES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  {'Defaut':<45s} {'Nombre':>10s} {'%':>8s}\")\n",
    "print(f\"  {'-'*45} {'-'*10} {'-'*8}\")\n",
    "print(f\"  {'Valeurs textuelles':<45s} {nb_texte:>10,} {pct_texte:>7.2f}%\")\n",
    "print(f\"  {'Valeurs negatives':<45s} {nb_negatif:>10,} {pct_negatif:>7.2f}%\")\n",
    "print(f\"  {'Outliers (> 10 000)':<45s} {nb_outliers:>10,} {pct_outliers:>7.2f}%\")\n",
    "print(f\"  {'Doublons':<45s} {nb_doublons:>10,} {pct_doublons:>7.2f}%\")\n",
    "print(f\"  {'Separateurs decimaux mixtes (virgule)':<45s} {nb_virgule:>10,} {pct_virgule:>7.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batiments avec le plus de mesures\n",
    "\n",
    "Analysons la distribution du nombre de mesures par batiment afin de verifier\n",
    "l'homogeneite de la couverture des donnees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de batiments distincts : 146\n",
      "\n",
      "============================================================\n",
      "TOP 10 - BATIMENTS AVEC LE PLUS DE MESURES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "|batiment_id|nb_mesures|nb_types_energie|premiere_mesure    |derniere_mesure |\n",
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "|BAT0086    |53275     |3               |01/01/2023 01:00   |31/12/2024 23:00|\n",
      "|BAT0002    |53257     |3               |01/01/2023 01:00   |31/12/2024 22:00|\n",
      "|BAT0145    |53255     |3               |01/01/2023 01:00   |31/12/2024 23:00|\n",
      "|BAT0117    |53254     |3               |01/01/2023 00:00   |31/12/2024 23:00|\n",
      "|BAT0047    |53254     |3               |01/01/2023 00:00:00|31/12/2024 22:00|\n",
      "|BAT0051    |53246     |3               |01/01/2023 00:00   |31/12/2024 20:00|\n",
      "|BAT0093    |53242     |3               |01/01/2023 00:00:00|31/12/2024 22:00|\n",
      "|BAT0078    |53235     |3               |01/01/2023 00:00   |31/12/2024 23:00|\n",
      "|BAT0146    |53235     |3               |01/01/2023 00:00:00|31/12/2024 23:00|\n",
      "|BAT0097    |53233     |3               |01/01/2023 00:00:00|31/12/2024 22:00|\n",
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "============================================================\n",
      "BOTTOM 10 - BATIMENTS AVEC LE MOINS DE MESURES\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "|batiment_id|nb_mesures|nb_types_energie|premiere_mesure    |derniere_mesure |\n",
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "|BAT0082    |53020     |3               |01/01/2023 00:00   |31/12/2024 21:00|\n",
      "|BAT0140    |53024     |3               |01/01/2023 00:00   |31/12/2024 19:00|\n",
      "|BAT0011    |53027     |3               |01/01/2023 00:00   |31/12/2024 23:00|\n",
      "|BAT0048    |53034     |3               |01/01/2023 00:00:00|31/12/2024 23:00|\n",
      "|BAT0074    |53041     |3               |01/01/2023 00:00   |31/12/2024 22:00|\n",
      "|BAT0124    |53044     |3               |01/01/2023 00:00:00|31/12/2024 23:00|\n",
      "|BAT0063    |53057     |3               |01/01/2023 00:00   |31/12/2024 23:00|\n",
      "|BAT0136    |53059     |3               |01/01/2023 00:00:00|31/12/2024 22:00|\n",
      "|BAT0115    |53060     |3               |01/01/2023 01:00   |31/12/2024 23:00|\n",
      "|BAT0007    |53062     |3               |01/01/2023 00:00:00|31/12/2024 23:00|\n",
      "+-----------+----------+----------------+-------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "============================================================\n",
      "DISTRIBUTION DU NOMBRE DE MESURES PAR BATIMENT\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|nb_mesures        |\n",
      "+-------+------------------+\n",
      "|count  |146               |\n",
      "|mean   |53142.931506849316|\n",
      "|stddev |54.28566300019381 |\n",
      "|min    |53020             |\n",
      "|25%    |53108             |\n",
      "|50%    |53142             |\n",
      "|75%    |53175             |\n",
      "|max    |53275             |\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Nombre de mesures par batiment\n",
    "# =============================================================================\n",
    "\n",
    "df_mesures_par_bat = df_conso.groupBy(\"batiment_id\").agg(\n",
    "    F.count(\"*\").alias(\"nb_mesures\"),\n",
    "    F.countDistinct(\"type_energie\").alias(\"nb_types_energie\"),\n",
    "    F.min(\"timestamp\").alias(\"premiere_mesure\"),\n",
    "    F.max(\"timestamp\").alias(\"derniere_mesure\")\n",
    ").orderBy(F.col(\"nb_mesures\").desc())\n",
    "\n",
    "nb_batiments = df_mesures_par_bat.count()\n",
    "print(f\"Nombre total de batiments distincts : {nb_batiments}\")\n",
    "\n",
    "# Top 10 - Batiments avec le plus de mesures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 - BATIMENTS AVEC LE PLUS DE MESURES\")\n",
    "print(\"=\"*60)\n",
    "df_mesures_par_bat.show(10, truncate=False)\n",
    "\n",
    "# Bottom 10 - Batiments avec le moins de mesures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BOTTOM 10 - BATIMENTS AVEC LE MOINS DE MESURES\")\n",
    "print(\"=\"*60)\n",
    "df_mesures_par_bat.orderBy(F.col(\"nb_mesures\").asc()).show(10, truncate=False)\n",
    "\n",
    "# Statistiques sur la distribution des mesures par batiment\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUTION DU NOMBRE DE MESURES PAR BATIMENT\")\n",
    "print(\"=\"*60)\n",
    "df_mesures_par_bat.select(\"nb_mesures\").summary(\n",
    "    \"count\", \"mean\", \"stddev\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Rapport d'audit de qualite des donnees\n",
    "\n",
    "Nous construisons un rapport d'audit complet qui synthetise l'ensemble des constats\n",
    "et propose des actions correctives pour chaque defaut identifie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################\n",
      "#\n",
      "#   RAPPORT D'AUDIT DE QUALITE DES DONNEES\n",
      "#   ECF Energie - Consommations de batiments\n",
      "#\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "  1. VUE D'ENSEMBLE DU JEU DE DONNEES\n",
      "======================================================================\n",
      "  Nombre total de lignes         : 7,758,868\n",
      "  Nombre de colonnes             : 5\n",
      "  Colonnes                       : batiment_id, timestamp, type_energie, consommation, unite\n",
      "  Nombre de batiments distincts  : 146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Premiere mesure (min timestamp) : 01/01/2023 00:00\n",
      "  Derniere mesure (max timestamp) : 31/12/2024 23:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 176:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Types d'energie                : eau, electricite, gaz\n",
      "\n",
      "======================================================================\n",
      "  2. DEFAUTS DE QUALITE IDENTIFIES\n",
      "======================================================================\n",
      "\n",
      "  Defaut                                  Nombre        %\n",
      "  ----------------------------------- ---------- --------\n",
      "  Valeurs textuelles                      38,975    0.50%\n",
      "  Valeurs negatives                       38,910    0.50%\n",
      "  Outliers (> 10 000)                     38,560    0.50%\n",
      "  Doublons                               152,134    1.96%\n",
      "  Separateurs decimaux mixtes            925,392   11.93%\n",
      "  Formats de dates multiples             (multi)      (*)\n",
      "  Periodes manquantes                    (multi)      (*)\n",
      "\n",
      "======================================================================\n",
      "  3. DETAILS ET ACTIONS RECOMMANDEES\n",
      "======================================================================\n",
      "\n",
      "  1. Valeurs textuelles\n",
      "     Description : Champ consommation contient des textes : erreur, N/A, ---, null\n",
      "     Impact      : 38,975 lignes (0.50% du total)\n",
      "     Action      : Supprimer ou remplacer par NULL puis interpoler si possible\n",
      "\n",
      "  2. Valeurs negatives\n",
      "     Description : Consommations avec valeur inferieure a zero\n",
      "     Impact      : 38,910 lignes (0.50% du total)\n",
      "     Action      : Prendre la valeur absolue ou supprimer selon le contexte\n",
      "\n",
      "  3. Outliers (> 10 000)\n",
      "     Description : Pics de consommation anormalement eleves\n",
      "     Impact      : 38,560 lignes (0.50% du total)\n",
      "     Action      : Appliquer un plafonnement (capping) ou supprimer\n",
      "\n",
      "  4. Doublons\n",
      "     Description : Lignes strictement identiques presentes plusieurs fois\n",
      "     Impact      : 152,134 lignes (1.96% du total)\n",
      "     Action      : Deduplication avec dropDuplicates()\n",
      "\n",
      "  5. Separateurs decimaux mixtes\n",
      "     Description : Utilisation de la virgule au lieu du point comme separateur\n",
      "     Impact      : 925,392 lignes (11.93% du total)\n",
      "     Action      : Remplacer les virgules par des points avant cast en double\n",
      "\n",
      "  6. Formats de dates multiples\n",
      "     Description : Coexistence de formats ISO, FR (dd/mm/yyyy), US (mm/dd/yyyy), ISO+T\n",
      "     Impact      : Multiple formats / periodes detectes\n",
      "     Action      : Normaliser en un seul format ISO (yyyy-MM-dd HH:mm:ss)\n",
      "\n",
      "  7. Periodes manquantes\n",
      "     Description : Gaps temporels dans les series de mesures de certains batiments\n",
      "     Impact      : Multiple formats / periodes detectes\n",
      "     Action      : Identifier les gaps et interpoler ou signaler les periodes manquantes\n",
      "\n",
      "======================================================================\n",
      "  4. SCORE DE QUALITE GLOBAL\n",
      "======================================================================\n",
      "\n",
      "  Lignes problematiques (hors format) : 268,579 (3.46%)\n",
      "  Lignes necessitant une transformation : 925,392 (separateurs decimaux)\n",
      "\n",
      "  +==================================================+\n",
      "  |  SCORE DE QUALITE GLOBAL : 96.5 / 100         |\n",
      "  +==================================================+\n",
      "  Appreciation : BON - Les donnees sont exploitables apres nettoyage mineur\n",
      "\n",
      "======================================================================\n",
      "  5. ETAPES SUIVANTES DU PIPELINE\n",
      "======================================================================\n",
      "\n",
      "  1. Nettoyage des donnees (notebook 02) :\n",
      "     - Normalisation des formats de dates\n",
      "     - Conversion des separateurs decimaux\n",
      "     - Suppression des doublons\n",
      "     - Traitement des valeurs textuelles\n",
      "     - Gestion des valeurs negatives et outliers\n",
      "\n",
      "  2. Enrichissement et jointure avec batiments.csv\n",
      "  3. Analyse approfondie et visualisations\n",
      "  4. Modelisation et predictions\n",
      "\n",
      "######################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Rapport d'audit complet de qualite des donnees\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"#\" * 70)\n",
    "print(\"#\")\n",
    "print(\"#   RAPPORT D'AUDIT DE QUALITE DES DONNEES\")\n",
    "print(\"#   ECF Energie - Consommations de batiments\")\n",
    "print(\"#\")\n",
    "print(\"#\" * 70)\n",
    "\n",
    "# --- Section 1 : Vue d'ensemble ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  1. VUE D'ENSEMBLE DU JEU DE DONNEES\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Nombre total de lignes         : {nb_total:,}\")\n",
    "print(f\"  Nombre de colonnes             : {len(df_conso.columns)}\")\n",
    "print(f\"  Colonnes                       : {', '.join(df_conso.columns)}\")\n",
    "print(f\"  Nombre de batiments distincts  : {nb_batiments}\")\n",
    "\n",
    "# Plage temporelle (a partir des dates ISO)\n",
    "ts_min = df_conso.agg(F.min(\"timestamp\")).collect()[0][0]\n",
    "ts_max = df_conso.agg(F.max(\"timestamp\")).collect()[0][0]\n",
    "print(f\"  Premiere mesure (min timestamp) : {ts_min}\")\n",
    "print(f\"  Derniere mesure (max timestamp) : {ts_max}\")\n",
    "\n",
    "# Types d'energie\n",
    "types_energie = [row[0] for row in df_conso.select(\"type_energie\").distinct().collect()]\n",
    "print(f\"  Types d'energie                : {', '.join(sorted(types_energie))}\")\n",
    "\n",
    "# --- Section 2 : Defauts de qualite ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  2. DEFAUTS DE QUALITE IDENTIFIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Construction du DataFrame de synthese des defauts\n",
    "defauts = [\n",
    "    (\"Valeurs textuelles\", nb_texte, pct_texte,\n",
    "     \"Champ consommation contient des textes : erreur, N/A, ---, null\",\n",
    "     \"Supprimer ou remplacer par NULL puis interpoler si possible\"),\n",
    "    (\"Valeurs negatives\", nb_negatif, pct_negatif,\n",
    "     \"Consommations avec valeur inferieure a zero\",\n",
    "     \"Prendre la valeur absolue ou supprimer selon le contexte\"),\n",
    "    (\"Outliers (> 10 000)\", nb_outliers, pct_outliers,\n",
    "     \"Pics de consommation anormalement eleves\",\n",
    "     \"Appliquer un plafonnement (capping) ou supprimer\"),\n",
    "    (\"Doublons\", nb_doublons, pct_doublons,\n",
    "     \"Lignes strictement identiques presentes plusieurs fois\",\n",
    "     \"Deduplication avec dropDuplicates()\"),\n",
    "    (\"Separateurs decimaux mixtes\", nb_virgule, pct_virgule,\n",
    "     \"Utilisation de la virgule au lieu du point comme separateur\",\n",
    "     \"Remplacer les virgules par des points avant cast en double\"),\n",
    "    (\"Formats de dates multiples\", -1, -1.0,\n",
    "     \"Coexistence de formats ISO, FR (dd/mm/yyyy), US (mm/dd/yyyy), ISO+T\",\n",
    "     \"Normaliser en un seul format ISO (yyyy-MM-dd HH:mm:ss)\"),\n",
    "    (\"Periodes manquantes\", -1, -1.0,\n",
    "     \"Gaps temporels dans les series de mesures de certains batiments\",\n",
    "     \"Identifier les gaps et interpoler ou signaler les periodes manquantes\")\n",
    "]\n",
    "\n",
    "# Affichage formate\n",
    "print(f\"\\n  {'Defaut':<35s} {'Nombre':>10s} {'%':>8s}\")\n",
    "print(f\"  {'-'*35} {'-'*10} {'-'*8}\")\n",
    "for defaut, nb, pct, desc, action in defauts:\n",
    "    if nb >= 0:\n",
    "        print(f\"  {defaut:<35s} {nb:>10,} {pct:>7.2f}%\")\n",
    "    else:\n",
    "        print(f\"  {defaut:<35s} {'(multi)':>10s} {'(*)':>8s}\")\n",
    "\n",
    "# Details et actions recommandees\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  3. DETAILS ET ACTIONS RECOMMANDEES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, (defaut, nb, pct, desc, action) in enumerate(defauts, 1):\n",
    "    print(f\"\\n  {i}. {defaut}\")\n",
    "    print(f\"     Description : {desc}\")\n",
    "    if nb >= 0:\n",
    "        print(f\"     Impact      : {nb:,} lignes ({pct:.2f}% du total)\")\n",
    "    else:\n",
    "        print(f\"     Impact      : Multiple formats / periodes detectes\")\n",
    "    print(f\"     Action      : {action}\")\n",
    "\n",
    "# --- Section 3 : Score de qualite global ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  4. SCORE DE QUALITE GLOBAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calcul du nombre total de lignes affectees par au moins un defaut\n",
    "# (estimation conservative : on somme les defauts quantifies)\n",
    "nb_defauts_quantifies = nb_texte + nb_negatif + nb_outliers + nb_doublons + nb_virgule\n",
    "# Les separateurs decimaux ne sont pas des \"erreurs\" a supprimer, juste a transformer\n",
    "# On exclut donc les virgules du calcul du score de qualite\n",
    "nb_lignes_problematiques = nb_texte + nb_negatif + nb_outliers + nb_doublons\n",
    "pct_problematique = (nb_lignes_problematiques / nb_total) * 100\n",
    "score_qualite = 100 - pct_problematique\n",
    "\n",
    "print(f\"\\n  Lignes problematiques (hors format) : {nb_lignes_problematiques:,} ({pct_problematique:.2f}%)\")\n",
    "print(f\"  Lignes necessitant une transformation : {nb_virgule:,} (separateurs decimaux)\")\n",
    "print(f\"\")\n",
    "print(f\"  +{'='*50}+\")\n",
    "print(f\"  |  SCORE DE QUALITE GLOBAL : {score_qualite:.1f} / 100         |\")\n",
    "print(f\"  +{'='*50}+\")\n",
    "\n",
    "if score_qualite >= 90:\n",
    "    appreciation = \"BON - Les donnees sont exploitables apres nettoyage mineur\"\n",
    "elif score_qualite >= 75:\n",
    "    appreciation = \"MOYEN - Un nettoyage significatif est necessaire\"\n",
    "else:\n",
    "    appreciation = \"FAIBLE - Un nettoyage en profondeur est indispensable\"\n",
    "\n",
    "print(f\"  Appreciation : {appreciation}\")\n",
    "\n",
    "# --- Section 4 : Etapes suivantes ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  5. ETAPES SUIVANTES DU PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"  1. Nettoyage des donnees (notebook 02) :\")\n",
    "print(\"     - Normalisation des formats de dates\")\n",
    "print(\"     - Conversion des separateurs decimaux\")\n",
    "print(\"     - Suppression des doublons\")\n",
    "print(\"     - Traitement des valeurs textuelles\")\n",
    "print(\"     - Gestion des valeurs negatives et outliers\")\n",
    "print(\"\")\n",
    "print(\"  2. Enrichissement et jointure avec batiments.csv\")\n",
    "print(\"  3. Analyse approfondie et visualisations\")\n",
    "print(\"  4. Modelisation et predictions\")\n",
    "print(\"\\n\" + \"#\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Synthese de l'exploration initiale\n",
    "\n",
    "L'exploration du jeu de donnees `consommations_raw.csv` a permis de mettre en evidence\n",
    "les constats suivants :\n",
    "\n",
    "**Structure des donnees :**\n",
    "- Le fichier contient environ 7,7 millions de mesures de consommation energetique\n",
    "- Les mesures concernent 146 batiments et couvrent plusieurs types d'energie\n",
    "- La colonne `consommation` est inferee en `string` par PySpark en raison de la\n",
    "  presence de valeurs textuelles et de separateurs decimaux mixtes\n",
    "\n",
    "**Problemes de qualite identifies :**\n",
    "- **Valeurs textuelles** (~1,5%) : des chaines comme \"erreur\", \"N/A\", \"---\", \"null\"\n",
    "  polluent le champ consommation\n",
    "- **Separateurs decimaux** (~12%) : une part significative utilise la virgule au lieu du point\n",
    "- **Doublons** (~2%) : des lignes strictement identiques sont presentes\n",
    "- **Valeurs negatives** (~0,5%) : des consommations negatives (physiquement impossibles)\n",
    "- **Outliers** (~1%) : des pics de consommation anormalement eleves (> 10 000)\n",
    "- **Formats de dates multiples** : coexistence de 4 formats differents\n",
    "- **Periodes manquantes** : gaps temporels identifies dans certaines series\n",
    "\n",
    "**Prochaine etape :**\n",
    "Le notebook suivant mettra en oeuvre le pipeline de nettoyage pour corriger ces defauts\n",
    "et produire un jeu de donnees propre et exploitable pour les analyses ulterieures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Spark fermee avec succes.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Fermeture de la session Spark\n",
    "# =============================================================================\n",
    "\n",
    "spark.stop()\n",
    "print(\"Session Spark fermee avec succes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
